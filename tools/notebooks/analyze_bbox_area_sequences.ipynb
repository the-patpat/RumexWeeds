{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Connected to FiftyOne on port 5151 at 127.0.0.1.\n",
      "If you are not connecting to a remote session, you may need to start a new session and specify a port\n"
     ]
    }
   ],
   "source": [
    "import fiftyone as fo\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib widget \n",
    "import numpy as np\n",
    "import copy\n",
    "import scipy as sp\n",
    "\n",
    "dataset = fo.load_dataset(\"RumexWeeds\")\n",
    "session = fo.Session(dataset=dataset, auto=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Gets the sequence tags\n",
    "tags = set()\n",
    "for x in dataset.values(\"tags\"):\n",
    "    tags = tags.union(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "bbox_dict = {}\n",
    "for tag in tags:\n",
    "    if \"seq\" in tag:\n",
    "        sequence = dataset.match_tags(tag)\n",
    "        bbox_dict[tag ]= sequence.values(\"ground_truth_detections.detections.bounding_box\")\n",
    "        break        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class KalmanNd:\n",
    "    def __init__(self, x_initial, P_initial, H, R, F):\n",
    "        self.x_initial = x_initial\n",
    "        self.P_initial = P_initial\n",
    "        self.x = x_initial # mean_vector (states)\n",
    "        self.P = P_initial # covariance matrix\n",
    "        self.H = H #Observability matrix\n",
    "        self.R = R #Measurement uncertainty\n",
    "        self.F = F\n",
    "        self.x_hist = []\n",
    "        self.P_hist = []\n",
    "        self.updated = []\n",
    "        self.locked = False\n",
    "        self.I = np.eye(x_initial.shape[0])#np.zeros((x_initial.shape[0], x_initial.shape[0]))\n",
    "        #np.fill_diagonal(self.I, 1)\n",
    "    \n",
    "    def lock(self):\n",
    "        self.locked = True\n",
    "\n",
    "    def update(self, Z):\n",
    "        \"\"\"Kalman filter measurement update\n",
    "        Alters the object and updates the Kalman filter with a current measurement.\n",
    "        Paramaters\n",
    "        -----------\n",
    "        Z : ndarray \n",
    "            The measurements to use for the update\n",
    "        \"\"\"\n",
    "        if not self.locked:\n",
    "            y = Z.reshape(-1,1) - np.dot(self.H, self.x)\n",
    "            S = np.dot(np.dot(self.H,self.P), self.H.T) + self.R\n",
    "            K = np.dot(np.dot(self.P,self.H.T), np.linalg.pinv(S))\n",
    "            \n",
    "            #Removed the update, but rather overwrite the prediction with the update\n",
    "            self.x_hist[-1] = (copy.deepcopy(self.x))\n",
    "            self.x = self.x + np.dot(K,y)\n",
    "            self.P_hist.append(copy.deepcopy(self.P))\n",
    "            self.P = np.dot((self.I - np.dot(K, self.H)), self.P)\n",
    "            self.updated[-1] = True\n",
    "    def predict(self, u=None):\n",
    "        if not self.locked:\n",
    "            ### insert predict function\n",
    "            if u is None:\n",
    "                u = np.zeros_like(self.x)\n",
    "            self.x_hist.append(copy.deepcopy(self.x))\n",
    "            self.x = np.dot(self.F,self.x) + u\n",
    "            self.P_hist.append(copy.deepcopy(self.P))\n",
    "            self.P = np.dot(np.dot(self.F, self.P), self.F.T)\n",
    "            self.updated.append(False)\n",
    "    def get_ellipsis(self, conf=0.95):\n",
    "        \"\"\"Returns the center point, minor and major axis of the ellipsis\"\"\"\n",
    "        \n",
    "        #Get the observables (columns/rows)\n",
    "        axs = [x[0] for x in np.argwhere(self.H)]\n",
    "        #Construct the custom covariance matrix\n",
    "        P_sub = self.P[np.ix_(axs, axs)]\n",
    "        #Get the eigenvectors\n",
    "        ev, evec = sp.linalg.eig(P_sub)\n",
    "        conf_length = sp.stats.chi2.ppf(conf, P_sub.shape[0])\n",
    "        #Note that this is just half the length (so you can do center +- length)\n",
    "        axis_length = np.sqrt(ev*conf_length)\n",
    "        ord = np.argsort(axis_length)\n",
    "\n",
    "        #center, minor, major (actually, need to adjust this to be generalized to n-d, not only 2d)\n",
    "        return self.x[axs], axis_length[ord[0]]*(evec[ord[0]]/np.linalg.norm(evec[ord[0]])), axis_length[ord[1]]*(evec[ord[1]]/np.linalg.norm(evec[ord[1]]))\n",
    "\n",
    "    def reset(self):\n",
    "        self.__init__(self.x_initial, self.P_initial, self.H, self.R, self.F)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Given a sequence of frames, make a cv2 video of it:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2 \n",
    "import time\n",
    "from fiftyone.utils.patches import extract_patch\n",
    "\n",
    "def tlwhN2xyxy(box, width, height):\n",
    "    \"\"\"Compute the normalized top left corner normalized coordinates to top left bottom right xy coordinates\"\"\"\n",
    "    tl_x = box[0]*width\n",
    "    tl_y = box[1]*height\n",
    "    br_x = tl_x + box[2]*width\n",
    "    br_y = tl_y + box[3]*height\n",
    "\n",
    "    return (int(x) for x in (tl_x, tl_y, br_x, br_y))\n",
    " \n",
    "def draw_boxes(sample, field_color_map, conf_thresh=0.0):\n",
    "    img = cv2.imread(sample[\"filepath\"])\n",
    "    img_raw = copy.deepcopy(img)\n",
    "    for field in field_color_map.keys():\n",
    "        if sample[field] is not None:\n",
    "            for gt in sample[field].detections:\n",
    "                tl_x, tl_y, br_x, br_y = tlwhN2xyxy(gt.bounding_box, sample[\"metadata\"].width, sample[\"metadata\"].height)\n",
    "                if gt.confidence is not None:\n",
    "                    if gt.confidence > conf_thresh:\n",
    "                        img = cv2.rectangle(img, (tl_x, tl_y), (br_x, br_y), field_color_map[field], 5)\n",
    "                else:\n",
    "                    img = cv2.rectangle(img, (tl_x, tl_y), (br_x, br_y), field_color_map[field], 5)\n",
    "\n",
    "    return img, img_raw\n",
    "\n",
    "def plot_points(canvas, points):\n",
    "    if len(points) > 1:\n",
    "        \n",
    "        #Normalize the coordinates, first find max and min\n",
    "        max_x = max(points, key=lambda x:x[0])[0]\n",
    "        max_y = max(points, key=lambda x:x[1])[1]\n",
    "        min_x = min(points, key=lambda x:x[0])[0]\n",
    "        min_y = min(points, key=lambda x:x[1])[1]\n",
    "\n",
    "        #Scaling factors for the length of each axis\n",
    "        #A point's difference to the maximum of each axis is to be scaled\n",
    "        x_scale = canvas.shape[0] / (max_x - min_x)\n",
    "        y_scale = canvas.shape[1] / (max_y - min_y)\n",
    "\n",
    "        for point in points:\n",
    "            canvas = cv2.circle(canvas, (int((max_x-point[0])*x_scale), int((max_y - point[1])*y_scale)), 3, (0,0,255), cv2.FILLED)\n",
    "    else:\n",
    "        #Draw point\n",
    "        canvas = cv2.circle(canvas, [x//2 for x in canvas.shape[:2]], 3, (0,0,1), cv2.FILLED)\n",
    "    return canvas\n",
    "\n",
    "sift = cv2.SIFT_create()\n",
    "# sift = cv2.ORB_create(nfeatures=100000, edgeThreshold=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Detection framework\n",
    "This is a rudimentary detection framework. It uses the ground truth as detections with a probability of 0.5 that there's a detection available. If there's a detection available, this gives us an ROI on which we can compute SIFT features for either validation in the next frame or as a fallback solution if the detector does not give a detection in the next frame. \n",
    "\n",
    "It also includes a kalman filter that can be used to further increase reliability - tracking the plants helps to counteract missing detections as we have a prediction of either a) ROI or b) center location (and the plant size should be constant if the plant is not currently moving out of or into the frame)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_3118/2048598360.py:120: ComplexWarning: Casting complex values to real discards the imaginary part\n",
      "  minor = minor.astype(int)\n",
      "/tmp/ipykernel_3118/2048598360.py:122: ComplexWarning: Casting complex values to real discards the imaginary part\n",
      "  major = major.astype(int)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SIFT Compute TIME 0\t Frame processing time: 0.802039623260498\t sift ratio = 0.0\t sift ratio = 0.4123803610325406\r"
     ]
    }
   ],
   "source": [
    "cv2.namedWindow(\"test\", cv2.WINDOW_NORMAL)\n",
    "sequence = dataset.match_tags(\"20210806_hegnstrup_seq11\")\n",
    "kp, des = None, None\n",
    "img3 = None\n",
    "traj = []\n",
    "match_count = []\n",
    "\n",
    "#Kalman filter initialization\n",
    "#TODO Needs calibration\n",
    "kmf = KalmanNd(np.asarray([[0], [0], [0], [0]]), \n",
    "                        1000*np.eye(4),\n",
    "                        np.asarray([[1, 0, 0, 0], [0, 0, 0, 0], [0, 0, 1, 0], [0, 0, 0, 0]]),\n",
    "                        np.asarray([[0.2, 0, 0, 0], [0, 0, 0, 0], [0, 0, 0.2, 0], [0, 0, 0, 0]]),\n",
    "                        np.asarray([[1, 1, 0, 0], [0, 1, 0, 0], [0, 0, 1, 1], [0, 0, 0, 1]]))\n",
    "\n",
    "# FLANN parameters\n",
    "FLANN_INDEX_KDTREE = 1\n",
    "index_params = dict(algorithm = FLANN_INDEX_KDTREE, trees = 5)\n",
    "search_params = dict(checks=50)   # or pass empty dictionary\n",
    "flann = cv2.FlannBasedMatcher(index_params,search_params)\n",
    "\n",
    "\n",
    "#Sequence loop\n",
    "for frame in sequence:\n",
    "\n",
    "    sift_time = 0\n",
    "    load_time = time.time()\n",
    "    img, img_raw = draw_boxes(frame, {\"ground_truth_detections_single\" : (255,0,0),  \"predictions_yolov4_csp_single\" : (0,255,0)}, 0.5)\n",
    "    \n",
    "\n",
    "    #Use OpenCV to plot GPS path\n",
    "    canvas = np.zeros((1000,1000,3), dtype=np.uint8)\n",
    "    traj.append(frame[\"location\"].point)\n",
    "    canvas = plot_points(canvas, traj)\n",
    "    \n",
    "    #Kalman filter prediction\n",
    "    #Necessary / protocol for each step\n",
    "    kmf.predict()\n",
    "\n",
    "    if frame[\"ground_truth_detections_single\"] is not None:\n",
    "        \n",
    "        #Box and center extracted from ground truth (prototype detection)\n",
    "        box = frame[\"ground_truth_detections_single\"].detections[0].bounding_box\n",
    "        center = (box[0] + 0.5*box[2], box[1] + 0.5*box[3])\n",
    "\n",
    "        #Simulate availability with binomial draw, reliability -> probability\n",
    "        #TODO replace this by a detectors output\n",
    "        detection_available = np.random.binomial(1,0.5,1)\n",
    "\n",
    "        #Create the mask for the box in preparation for sift computation\n",
    "        #This would correspond to a detection -> gives RoI -> compute features from that and match it in the next\n",
    "        # a) Detection to verify\n",
    "        # b) Whole image to track RoI when no detection is there\n",
    "        if detection_available:\n",
    "            #Give me an ROI to detect features from\n",
    "            tl_x, tl_y, br_x, br_y = tlwhN2xyxy(box, frame[\"metadata\"].width, frame[\"metadata\"].height)        \n",
    "            box_mask = np.zeros((frame[\"metadata\"].height, frame[\"metadata\"].width), dtype=np.uint8)\n",
    "            box_mask[tl_y:(br_y+1), tl_x:(br_x+1)] = 1\n",
    "        else:\n",
    "            #Search for features in the whole frame\n",
    "            box_mask = None\n",
    "\n",
    "        #-----Compute the features---------\n",
    "        \n",
    "        #Timing the sift detection\n",
    "        start_time = time.time()\n",
    "        kp_curr, des_curr = sift.detectAndCompute(cv2.cvtColor(img_raw, cv2.COLOR_BGR2GRAY), box_mask)# if np.random.binomial(1,0.5,1) else None)\n",
    "        end_time = time.time()\n",
    "        sift_time += (end_time - start_time)\n",
    "\n",
    "        if kp is not None and des is not None:\n",
    "            \n",
    "            #Timing the flann matcher\n",
    "            start_time = time.time()\n",
    "            matches = flann.knnMatch(des, des_curr, k=2)\n",
    "            end_time = time.time()\n",
    "            sift_time += (end_time - start_time)\n",
    "            #match_count.append(len(matches)) \n",
    "\n",
    "            #Copied from OpenCV SIFT tutorial\n",
    "            # Need to draw only good matches, so create a mask\n",
    "            matchesMask = [[0,0] for i in range(len(matches))]\n",
    "            # ratio test as per Lowe's paper\n",
    "            for i,(m,n) in enumerate(matches):\n",
    "                if m.distance < 0.7*n.distance:\n",
    "                    matchesMask[i]=[1,0]\n",
    "            match_count.append(np.asarray(matchesMask).sum(axis=0)[0])\n",
    "\n",
    "            #TODO maybe move this out of the loop to only change the matchesMask value\n",
    "            draw_params = dict(matchColor = (0,255,0),\n",
    "                            singlePointColor = (255,0,0),\n",
    "                            matchesMask = matchesMask,\n",
    "                            flags = cv2.DrawMatchesFlags_DEFAULT)\n",
    "            img3 = cv2.drawMatchesKnn(img_prev,kp,img,kp_curr,matches,None,**draw_params)\n",
    "\n",
    "        #Keep keypoints and descriptors for next iteration (we have to)\n",
    "        #Think about the keypoints to keep when no detection is available and we do kalman/sift based tracking\n",
    "        #We only keep keypoints from detections (RoI keypoints)\n",
    "        if detection_available:\n",
    "            kp = kp_curr\n",
    "            des = des_curr \n",
    "            img_prev = img\n",
    "            \n",
    "            #Update the kalman filter as we have a detection\n",
    "            kmf.update(np.asarray([center[0], 0, center[1], 0]).reshape(-1,1))\n",
    "            \n",
    "            #Draw update point\n",
    "            cv2.circle(img, (int(center[0]*frame[\"metadata\"].width), int(center[1]*frame[\"metadata\"].height)), 10, (0,255, 0), cv2.FILLED)\n",
    "\n",
    "    canvas = np.pad(canvas, ((100,100), (460, 460), (0,0)), 'constant', constant_values=((0,0),(0,0),(0,0)))\n",
    "\n",
    "    #Draw kalman filter point on image\n",
    "    img = cv2.circle(img, (int(kmf.x_hist[-1][0]*frame[\"metadata\"].width), int(kmf.x_hist[-1][2]*frame[\"metadata\"].height)), 10, ((255, 0, 0) if kmf.updated[-1] else (0,0,255)), cv2.FILLED)\n",
    "\n",
    "    #-----------------Ellipsis drawing begin\n",
    "    center, minor, major = kmf.get_ellipsis(conf=0.5)\n",
    "    center = center.flatten() * np.asarray((frame[\"metadata\"].width, frame[\"metadata\"].height))\n",
    "    center = center.astype(int)\n",
    "    minor *= np.asarray((frame[\"metadata\"].width, frame[\"metadata\"].height))\n",
    "    minor = minor.astype(int)\n",
    "    major *= np.asarray((frame[\"metadata\"].width, frame[\"metadata\"].height))\n",
    "    major = major.astype(int)\n",
    "    #Draw kalman ellipsis onto image, angle is of major axis, + -> cw, - -> ccw\n",
    "    img = cv2.ellipse(img, center, (np.linalg.norm(major).astype(int), np.linalg.norm(minor).astype(int)), -np.arctan2(major[1], major[0]), 0, 360, ((255, 0, 0) if kmf.updated[-1] else (0,0,255)), 10)\n",
    "    #-----------------Ellipsis drawing end\n",
    "\n",
    "\n",
    "    #Save for next iteration\n",
    "    #img_prev = copy.deepcopy(img) \n",
    "    \n",
    "    #Merge plot and image together and display it\n",
    "    img = np.hstack((img, canvas))\n",
    "    if img3 is not None:\n",
    "        img = np.vstack((img, img3))\n",
    "    cv2.imshow(\"test\", img)\n",
    "    end_end_time = time.time()\n",
    "    print(f\"SIFT Compute TIME {sift_time}\\t Frame processing time: {end_end_time - load_time}\\t sift ratio = {sift_time/(end_end_time - load_time)}\\r\", end=\"\")\n",
    "    cv2.waitKey(1)\n",
    "    if chr(cv2.waitKey(0)) == 'q':\n",
    "        break\n",
    "    else:\n",
    "        pass\n",
    "    #max(1, int(abs(1e-3 - (time.time() - load_time)))*1000))\n",
    "    \n",
    "\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ORB matching and highlighting plant"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4.764175653457642\n",
      "0.7928662300109863\n",
      "0.5942831039428711\n",
      "0.5101413726806641\n",
      "0.6364800930023193\n",
      "0.6330032348632812\n",
      "0.6256186962127686\n",
      "0.4516603946685791\n",
      "0.7822990417480469\n",
      "0.7949268817901611\n",
      "0.46195554733276367\n",
      "0.8055150508880615\n",
      "0.4437098503112793\n",
      "0.627727746963501\n",
      "0.5535793304443359\n",
      "0.47097039222717285\n",
      "0.5631875991821289\n",
      "0.5836398601531982\n",
      "0.5688769817352295\n",
      "0.5684413909912109\n",
      "0.4457426071166992\n",
      "0.64237380027771\n",
      "0.5414631366729736\n",
      "0.444744348526001\n",
      "0.5780670642852783\n",
      "0.5513503551483154\n",
      "0.6259763240814209\n",
      "0.5216643810272217\n",
      "0.8962037563323975\n",
      "0.6449892520904541\n",
      "0.5851936340332031\n",
      "0.6386735439300537\n",
      "0.6127719879150391\n",
      "0.5734071731567383\n",
      "0.6078734397888184\n",
      "0.5947206020355225\n",
      "0.503727912902832\n",
      "0.59867262840271\n",
      "0.48845648765563965\n",
      "0.5087695121765137\n",
      "0.5581035614013672\n",
      "0.5241653919219971\n",
      "0.5275783538818359\n",
      "0.5003201961517334\n",
      "0.5118002891540527\n",
      "0.47351646423339844\n",
      "0.5006186962127686\n",
      "0.43473029136657715\n",
      "1.0479891300201416\n",
      "0.4256932735443115\n",
      "0.49250292778015137\n",
      "0.5769608020782471\n",
      "0.5367476940155029\n",
      "0.5097644329071045\n",
      "0.5168783664703369\n",
      "0.5630002021789551\n",
      "0.5004522800445557\n",
      "0.45064425468444824\n",
      "0.5226035118103027\n",
      "0.46981096267700195\n",
      "0.5323736667633057\n",
      "0.44037818908691406\n",
      "0.4410066604614258\n",
      "0.4707942008972168\n",
      "0.5392985343933105\n",
      "0.5101408958435059\n",
      "0.5537014007568359\n",
      "0.495741605758667\n",
      "0.5308268070220947\n",
      "0.6171398162841797\n",
      "0.558927059173584\n",
      "0.4758288860321045\n",
      "0.43149590492248535\n",
      "0.4441862106323242\n",
      "0.48099255561828613\n",
      "0.5140509605407715\n",
      "0.5806512832641602\n",
      "0.46256589889526367\n",
      "0.4521608352661133\n",
      "0.4398307800292969\n",
      "0.5084052085876465\n",
      "0.5633816719055176\n",
      "0.5624141693115234\n",
      "0.5011003017425537\n",
      "0.48722076416015625\n",
      "0.4510989189147949\n",
      "0.45908498764038086\n",
      "0.5292496681213379\n",
      "0.552701473236084\n",
      "0.5106465816497803\n",
      "0.4905083179473877\n",
      "0.5147087574005127\n",
      "0.4334568977355957\n",
      "0.5246999263763428\n",
      "0.5000388622283936\n",
      "0.5467393398284912\n",
      "0.6415162086486816\n",
      "2.510093927383423\n",
      "1.145193338394165\n",
      "0.8291254043579102\n",
      "0.9069440364837646\n",
      "0.4453725814819336\n",
      "0.4863564968109131\n",
      "0.3889174461364746\n",
      "0.46629905700683594\n",
      "0.3624570369720459\n",
      "0.3996415138244629\n",
      "0.4228076934814453\n",
      "0.44468235969543457\n",
      "0.4834299087524414\n",
      "0.3745262622833252\n",
      "0.34813666343688965\n",
      "0.38295674324035645\n",
      "0.3500032424926758\n",
      "0.34232068061828613\n",
      "0.3444666862487793\n",
      "0.36031126976013184\n",
      "0.34644365310668945\n",
      "0.3872642517089844\n",
      "0.39204907417297363\n",
      "0.37979626655578613\n",
      "0.4104163646697998\n",
      "0.37426280975341797\n",
      "0.3606400489807129\n",
      "0.37960195541381836\n",
      "0.3706932067871094\n",
      "0.3496396541595459\n",
      "0.3501288890838623\n",
      "0.3618776798248291\n",
      "0.39339423179626465\n",
      "0.38159656524658203\n",
      "0.36475706100463867\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0fdee0045ae045219056516793b518e8",
       "version_major": 2,
       "version_minor": 0
      },
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAoAAAAHgCAYAAAA10dzkAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjUuMSwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/YYfK9AAAACXBIWXMAAA9hAAAPYQGoP6dpAAAOYklEQVR4nO3YwWvXdRzH8Y/xc8NcOJ2kQ52DuZZZ2GbY9OBJiOgmSBBdAy+dvHjtH+hQ924R4SmCDtHAghAPKusglpNKHKWiP6ftN2XZr//i/XO8Ho9/4PXeT/ny5LOp3+/3GwAAMV4Y9AEAANQSgAAAYQQgAEAYAQgAEEYAAgCEEYAAAGEEIABAGAEIABBGAAIAhBGAAABhBCAAQBgBCAAQRgACAIQRgAAAYQQgAEAYAQgAEEYAAgCEEYAAAGEEIABAGAEIABBGAAIAhBGAAABhBCAAQBgBCAAQRgACAIQRgAAAYQQgAEAYAQgAEEYAAgCEEYAAAGEEIABAGAEIABBGAAIAhBGAAABhBCAAQBgBCAAQRgACAIQRgAAAYQQgAEAYAQgAEEYAAgCEEYAAAGEEIABAGAEIABBGAAIAhBGAAABhBCAAQBgBCAAQRgACAIQRgAAAYQQgAEAYAQgAEEYAAgCEEYAAAGEEIABAGAEIABBGAAIAhOkM+oCN7uTJkyU7vV6vZGd8fLxkZ/PmzSU7lZ48eVKys3PnzpKd+fn5kp3ff/+9ZGdiYqJk58CBAyU73W63ZGd6erpk5+HDhyU7ld+excXFkp2///67ZGfr1q0lO6urqyU7n3zyScnO88oLIABAGAEIABBGAAIAhBGAAABhBCAAQBgBCAAQRgACAIQRgAAAYQQgAEAYAQgAEEYAAgCEEYAAAGEEIABAGAEIABBGAAIAhBGAAABhBCAAQBgBCAAQRgACAIQRgAAAYQQgAEAYAQgAEEYAAgCEEYAAAGEEIABAGAEIABBGAAIAhBGAAABhBCAAQJjOoA/Y6F577bWSnWvXrpXsvPXWWyU7jx49KtlZXV0t2WmtteXl5ZKd/fv3l+w8efKkZGdkZKRk54033ijZWV9fL9kZGxsr2Tlw4EDJzsrKSsnO3bt3S3Zaa+3tt98u2el2uyU73333XcnOgwcPSnbSeQEEAAgjAAEAwghAAIAwAhAAIIwABAAIIwABAMIIQACAMAIQACCMAAQACCMAAQDCCEAAgDACEAAgjAAEAAgjAAEAwghAAIAwAhAAIIwABAAIIwABAMIIQACAMAIQACCMAAQACCMAAQDCCEAAgDACEAAgjAAEAAgjAAEAwghAAIAwAhAAIIwABAAIIwABAMJ0Bn3ARjc8PFyyMzY2VrKzuLhYsrN58+aSndHR0ZKd1lrbtWtXyc6dO3dKdqp+u9dff71kp+r/3PHjx0t2fvrpp5Kdr776qmRnfHy8ZGd2drZkp7XWbt68WbIzNDRUsrO+vl6yMzMzU7KTzgsgAEAYAQgAEEYAAgCEEYAAAGEEIABAGAEIABBGAAIAhBGAAABhBCAAQBgBCAAQRgACAIQRgAAAYQQgAEAYAQgAEEYAAgCEEYAAAGEEIABAGAEIABBGAAIAhBGAAABhBCAAQBgBCAAQRgACAIQRgAAAYQQgAEAYAQgAEEYAAgCEEYAAAGEEIABAGAEIABCmM+gDNrrHjx+X7KytrZXsLC0tlex8+OGHJTt79uwp2WmttdHR0ZKdiYmJkp3z58+X7Dx79qxkZ3x8vGTn4sWLJTu//vpryc7WrVtLdqpcvXq1bOvevXslOyMjIyU7d+7cKdn59ttvS3bOnTtXsvO88gIIABBGAAIAhBGAAABhBCAAQBgBCAAQRgACAIQRgAAAYQQgAEAYAQgAEEYAAgCEEYAAAGEEIABAGAEIABBGAAIAhBGAAABhBCAAQBgBCAAQRgACAIQRgAAAYQQgAEAYAQgAEEYAAgCEEYAAAGEEIABAGAEIABBGAAIAhBGAAABhBCAAQBgBCAAQRgACAITpDPqAja7b7ZbszMzMlOzMzs6W7KysrJTsPH78uGSntdbu3btXsnPixImSnfn5+ZKdTqfmM7Rt27aSnc8//7xk5+DBgyU7x48fL9n59NNPS3a2b99estNaa3NzcyU7CwsLJTtVv92pU6dKdtJ5AQQACCMAAQDCCEAAgDACEAAgjAAEAAgjAAEAwghAAIAwAhAAIIwABAAIIwABAMIIQACAMAIQACCMAAQACCMAAQDCCEAAgDACEAAgjAAEAAgjAAEAwghAAIAwAhAAIIwABAAIIwABAMIIQACAMAIQACCMAAQACCMAAQDCCEAAgDACEAAgjAAEAAgjAAEAwnQGfcBG9/Tp05Kd8fHxkp2ZmZmSnfPnz5fsVP1urbU2NTVVsrN9+/aSnZGRkZKdpaWlkp1er1eyc+LEiZKd+/fvl+wsLCyU7Bw5cqRkZ3h4uGSntdbGxsZKdubm5kp2bt26VbJz+/btkp10XgABAMIIQACAMAIQACCMAAQACCMAAQDCCEAAgDACEAAgjAAEAAgjAAEAwghAAIAwAhAAIIwABAAIIwABAMIIQACAMAIQACCMAAQACCMAAQDCCEAAgDACEAAgjAAEAAgjAAEAwghAAIAwAhAAIIwABAAIIwABAMIIQACAMAIQACCMAAQACCMAAQDCdAZ9wEb3559/luz0er2SnR9++KFk55dffinZ2bVrV8lOa629+OKLJTs3btwo2Zmfny/ZOXjwYMnO5cuXS3bu379fsrO6ulqy88orr5TsfP311yU7k5OTJTuttfbee++V7Ozbt69k56+//irZmZiYKNlJ5wUQACCMAAQACCMAAQDCCEAAgDACEAAgjAAEAAgjAAEAwghAAIAwAhAAIIwABAAIIwABAMIIQACAMAIQACCMAAQACCMAAQDCCEAAgDACEAAgjAAEAAgjAAEAwghAAIAwAhAAIIwABAAIIwABAMIIQACAMAIQACCMAAQACCMAAQDCCEAAgDACEAAgjAAEAAizqd/v9wd9xEZ2+vTpkp1t27aV7ExNTZXsXL9+vWTn5ZdfLtlprbVjx46V7Pzxxx8lO91ut2Tn5MmTJTtXrlwp2VlYWCjZ2b17d8nOzZs3S3ZGR0dLdv7777+SndZaGxoaKtk5fPhwyc709HTJzmeffVay8/PPP5fsPK+8AAIAhBGAAABhBCAAQBgBCAAQRgACAIQRgAAAYQQgAEAYAQgAEEYAAgCEEYAAAGEEIABAGAEIABBGAAIAhBGAAABhBCAAQBgBCAAQRgACAIQRgAAAYQQgAEAYAQgAEEYAAgCEEYAAAGEEIABAGAEIABBGAAIAhBGAAABhBCAAQBgBCAAQRgACAIQRgAAAYTqDPmCj+/fff0t2pqamSnaOHj1asrO+vl6ys7KyUrLTWmtffPFFyc709HTJzuHDh0t2/vnnn5KdTqfmc3fp0qWSnbm5uZKd3bt3l+xU/fuMjo6W7LTW2gcffFCys7y8XLLT7XZLdnq9XslOOi+AAABhBCAAQBgBCAAQRgACAIQRgAAAYQQgAEAYAQgAEEYAAgCEEYAAAGEEIABAGAEIABBGAAIAhBGAAABhBCAAQBgBCAAQRgACAIQRgAAAYQQgAEAYAQgAEEYAAgCEEYAAAGEEIABAGAEIABBGAAIAhBGAAABhBCAAQBgBCAAQRgACAIQRgAAAYQQgAECYTf1+vz/oIzay2dnZkp3333+/ZGdoaKhk59ChQyU7Fy5cKNlprbVOp1Oy8/Dhw5Kd+fn5kp29e/eW7GzZsqVk5/r16yU7Z86cKdmp+ia88847JTsvvFD37nH37t2SnY8//rhkZ3FxsWTnyy+/LNn57bffSnaeV14AAQDCCEAAgDACEAAgjAAEAAgjAAEAwghAAIAwAhAAIIwABAAIIwABAMIIQACAMAIQACCMAAQACCMAAQDCCEAAgDACEAAgjAAEAAgjAAEAwghAAIAwAhAAIIwABAAIIwABAMIIQACAMAIQACCMAAQACCMAAQDCCEAAgDACEAAgjAAEAAgjAAEAwghAAIAwm/r9fn/QR2xkk5OTJTtbtmwp2fnoo49Kdi5fvlyys2PHjpKd1lrbs2dPyc7S0lLJzksvvVSys7a2VrJz7ty5kp1vvvmmZGd4eLhk58cffyzZ2bdvX8nOrVu3SnZaa+3o0aMlO0+fPi3ZuXDhQsnOxYsXS3YePXpUsvO88gIIABBGAAIAhBGAAABhBCAAQBgBCAAQRgACAIQRgAAAYQQgAEAYAQgAEEYAAgCEEYAAAGEEIABAGAEIABBGAAIAhBGAAABhBCAAQBgBCAAQRgACAIQRgAAAYQQgAEAYAQgAEEYAAgCEEYAAAGEEIABAGAEIABBGAAIAhBGAAABhBCAAQBgBCAAQpjPoAza6brdbsnP79u2SnbNnz5bsvPrqqyU7O3bsKNlprbX9+/eX7Kyvr5fsvPvuuyU7ExMTJTvXrl0r2ZmcnCzZefDgQclO1d+ztrZWstPr9Up2Wmvtxo0bJTvLy8slO99//33Jzptvvlmyk84LIABAGAEIABBGAAIAhBGAAABhBCAAQBgBCAAQRgACAIQRgAAAYQQgAEAYAQgAEEYAAgCEEYAAAGEEIABAGAEIABBGAAIAhBGAAABhBCAAQBgBCAAQRgACAIQRgAAAYQQgAEAYAQgAEEYAAgCEEYAAAGEEIABAGAEIABBGAAIAhBGAAABhBCAAQBgBCAAQZlO/3+8P+ggAAOp4AQQACCMAAQDCCEAAgDACEAAgjAAEAAgjAAEAwghAAIAwAhAAIIwABAAIIwABAMIIQACAMAIQACCMAAQACCMAAQDCCEAAgDACEAAgjAAEAAgjAAEAwghAAIAwAhAAIIwABAAIIwABAMIIQACAMAIQACCMAAQACCMAAQDCCEAAgDACEAAgjAAEAAgjAAEAwghAAIAwAhAAIIwABAAIIwABAMIIQACAMAIQACCMAAQACCMAAQDCCEAAgDACEAAgjAAEAAgjAAEAwghAAIAwAhAAIIwABAAIIwABAMIIQACAMAIQACCMAAQACCMAAQDCCEAAgDACEAAgzP+m+mDNsd6PqgAAAABJRU5ErkJggg==",
      "text/html": [
       "\n",
       "            <div style=\"display: inline-block;\">\n",
       "                <div class=\"jupyter-widgets widget-label\" style=\"text-align: center;\">\n",
       "                    Figure\n",
       "                </div>\n",
       "                <img src='data:image/png;base64,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' width=640.0/>\n",
       "            </div>\n",
       "        "
      ],
      "text/plain": [
       "Canvas(toolbar=Toolbar(toolitems=[('Home', 'Reset original view', 'home', 'home'), ('Back', 'Back to previous â€¦"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "cv2.namedWindow(\"test\", cv2.WINDOW_NORMAL)\n",
    "sequence = dataset.match_tags(\"20210806_hegnstrup_seq11\")\n",
    "kp_list = []\n",
    "for frame in sequence:\n",
    "    img = cv2.imread(frame.filepath)\n",
    "    #kp_list.append(sift.detect(cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)))# if np.random.binomial(1,0.5,1) else None))\n",
    "    start_time = time.time()\n",
    "    kp = sift.detect(cv2.cvtColor(img, cv2.COLOR_BGR2GRAY))\n",
    "    end_time = time.time()\n",
    "    sift_time = end_time - start_time\n",
    "    img, img_raw = draw_boxes(frame, {'ground_truth_detections_single' : (0,0,255)})\n",
    "    img = cv2.drawKeypoints(img ,kp,img, color=(255,0,0))\n",
    "    points = np.asarray([x.pt for x in kp])\n",
    "    h,x,y, _ = plt.hist2d(points[:, 0], points[:, 1], bins=(19,12), cmap='gray')\n",
    "    plt.axis('off')\n",
    "    plt.savefig(\"test.png\", bbox_inches='tight', pad_inches=0)\n",
    "    hist = cv2.resize(cv2.imread(\"test.png\"), (1920,1200))\n",
    "    hist = cv2.GaussianBlur(hist, (19,11), 10.0)\n",
    "    hist = np.flipud(hist)\n",
    "    #img = cv2.addWeighted(img, 1.3 , hist, -0.3, 0.0)\n",
    "    img_proc = cv2.addWeighted(img_raw, 1.3, hist, -0.3, 0.0)\n",
    "    img = np.hstack((img, img_proc))\n",
    "    img = np.vstack((img, np.hstack((img_raw, img_proc))))\n",
    "    cv2.imshow(\"test\", img)\n",
    "    cv2.waitKey(1)\n",
    "    print(sift_time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "area_fn = lambda x: x[2]*x[3]\n",
    "for key in bbox_dict:\n",
    "    area = []\n",
    "    box_count = []\n",
    "    detections = bbox_dict[key]\n",
    "    fig = plt.figure()\n",
    "    ax = plt.axes()\n",
    "    for detection in detections:\n",
    "        if detection is not None:\n",
    "            bbox_array = np.asarray(detection).reshape(-1,4)\n",
    "            area.append(np.cumsum(np.apply_along_axis(area_fn, 1, bbox_array)[-1]))\n",
    "            box_count.append(bbox_array.shape[0])\n",
    "    ax.plot(area)\n",
    "    ax.twinx().plot(box_count, color='yellow')\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# IMU, GPS and Odometry data\n",
    "This section analyzes the relationships between the data and how to make use of these to make a reliable weed detection framework "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "e42a55181f121158a42f92e69485864b9ecfda4e76420aabfd16d5b20265c656"
  },
  "kernelspec": {
   "display_name": "Python 3.9.10 ('yolov5')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
