{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import fiftyone as fo\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib widget \n",
    "import numpy as np\n",
    "import copy\n",
    "import scipy as sp\n",
    "\n",
    "dataset = fo.load_dataset(\"RumexWeeds\")\n",
    "session = fo.Session(dataset=dataset, auto=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Gets the sequence tags\n",
    "tags = set()\n",
    "for x in dataset.values(\"tags\"):\n",
    "    tags = tags.union(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "bbox_dict = {}\n",
    "for tag in tags:\n",
    "    if \"seq\" in tag:\n",
    "        sequence = dataset.match_tags(tag)\n",
    "        bbox_dict[tag ]= sequence.values(\"ground_truth_detections.detections.bounding_box\")\n",
    "        break        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class KalmanNd:\n",
    "    def __init__(self, x_initial, P_initial, H, R, F):\n",
    "        self.x_initial = x_initial\n",
    "        self.P_initial = P_initial\n",
    "        self.x = x_initial # mean_vector (states)\n",
    "        self.P = P_initial # covariance matrix\n",
    "        self.H = H #Observability matrix\n",
    "        self.R = R #Measurement uncertainty\n",
    "        self.F = F\n",
    "        self.x_hist = []\n",
    "        self.P_hist = []\n",
    "        self.updated = []\n",
    "        self.locked = False\n",
    "        self.I = np.eye(x_initial.shape[0])#np.zeros((x_initial.shape[0], x_initial.shape[0]))\n",
    "        #np.fill_diagonal(self.I, 1)\n",
    "    \n",
    "    def lock(self):\n",
    "        self.locked = True\n",
    "\n",
    "    def update(self, Z):\n",
    "        \"\"\"Kalman filter measurement update\n",
    "        Alters the object and updates the Kalman filter with a current measurement.\n",
    "        Paramaters\n",
    "        -----------\n",
    "        Z : ndarray \n",
    "            The measurements to use for the update\n",
    "        \"\"\"\n",
    "        if not self.locked:\n",
    "            y = Z.reshape(-1,1) - np.dot(self.H, self.x)\n",
    "            S = np.dot(np.dot(self.H,self.P), self.H.T) + self.R\n",
    "            K = np.dot(np.dot(self.P,self.H.T), np.linalg.pinv(S))\n",
    "            \n",
    "            #Removed the update, but rather overwrite the prediction with the update\n",
    "            self.x_hist[-1] = (copy.deepcopy(self.x))\n",
    "            self.x = self.x + np.dot(K,y)\n",
    "            self.P_hist.append(copy.deepcopy(self.P))\n",
    "            self.P = np.dot((self.I - np.dot(K, self.H)), self.P)\n",
    "            self.updated[-1] = True\n",
    "    def predict(self, u=None):\n",
    "        if not self.locked:\n",
    "            ### insert predict function\n",
    "            if u is None:\n",
    "                u = np.zeros_like(self.x)\n",
    "            self.x_hist.append(copy.deepcopy(self.x))\n",
    "            self.x = np.dot(self.F,self.x) + u\n",
    "            self.P_hist.append(copy.deepcopy(self.P))\n",
    "            self.P = np.dot(np.dot(self.F, self.P), self.F.T)\n",
    "            self.updated.append(False)\n",
    "    def get_ellipsis(self, conf=0.95):\n",
    "        \"\"\"Returns the center point, minor and major axis of the ellipsis\"\"\"\n",
    "        \n",
    "        #Get the observables (columns/rows)\n",
    "        axs = [x[0] for x in np.argwhere(self.H)]\n",
    "        #Construct the custom covariance matrix\n",
    "        P_sub = self.P[np.ix_(axs, axs)]\n",
    "        #Get the eigenvectors\n",
    "        ev, evec = sp.linalg.eig(P_sub)\n",
    "        conf_length = sp.stats.chi2.ppf(conf, P_sub.shape[0])\n",
    "        #Note that this is just half the length (so you can do center +- length)\n",
    "        axis_length = np.sqrt(ev*conf_length)\n",
    "        ord = np.argsort(axis_length)\n",
    "\n",
    "        #center, minor, major (actually, need to adjust this to be generalized to n-d, not only 2d)\n",
    "        return self.x[axs], axis_length[ord[0]]*(evec[ord[0]]/np.linalg.norm(evec[ord[0]])), axis_length[ord[1]]*(evec[ord[1]]/np.linalg.norm(evec[ord[1]]))\n",
    "\n",
    "    def reset(self):\n",
    "        self.__init__(self.x_initial, self.P_initial, self.H, self.R, self.F)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Given a sequence of frames, make a cv2 video of it:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2 \n",
    "import time\n",
    "from fiftyone.utils.patches import extract_patch\n",
    "\n",
    "def tlwhN2xyxy(box, width, height):\n",
    "    \"\"\"Compute the normalized top left corner normalized coordinates to top left bottom right xy coordinates\"\"\"\n",
    "    tl_x = box[0]*width\n",
    "    tl_y = box[1]*height\n",
    "    br_x = tl_x + box[2]*width\n",
    "    br_y = tl_y + box[3]*height\n",
    "\n",
    "    return (int(x) for x in (tl_x, tl_y, br_x, br_y))\n",
    " \n",
    "def draw_boxes(sample, field_color_map, conf_thresh=0.0):\n",
    "    img = cv2.imread(sample[\"filepath\"])\n",
    "    img_raw = copy.deepcopy(img)\n",
    "    for field in field_color_map.keys():\n",
    "        if sample[field] is not None:\n",
    "            for gt in sample[field].detections:\n",
    "                tl_x, tl_y, br_x, br_y = tlwhN2xyxy(gt.bounding_box, sample[\"metadata\"].width, sample[\"metadata\"].height)\n",
    "                if gt.confidence is not None:\n",
    "                    if gt.confidence > conf_thresh:\n",
    "                        img = cv2.rectangle(img, (tl_x, tl_y), (br_x, br_y), field_color_map[field], 5)\n",
    "                else:\n",
    "                    img = cv2.rectangle(img, (tl_x, tl_y), (br_x, br_y), field_color_map[field], 5)\n",
    "\n",
    "    return img, img_raw\n",
    "\n",
    "def plot_points(canvas, points):\n",
    "    if len(points) > 1:\n",
    "        \n",
    "        #Normalize the coordinates, first find max and min\n",
    "        max_x = max(points, key=lambda x:x[0])[0]\n",
    "        max_y = max(points, key=lambda x:x[1])[1]\n",
    "        min_x = min(points, key=lambda x:x[0])[0]\n",
    "        min_y = min(points, key=lambda x:x[1])[1]\n",
    "\n",
    "        #Scaling factors for the length of each axis\n",
    "        #A point's difference to the maximum of each axis is to be scaled\n",
    "        x_scale = canvas.shape[0] / (max_x - min_x)\n",
    "        y_scale = canvas.shape[1] / (max_y - min_y)\n",
    "\n",
    "        for point in points:\n",
    "            canvas = cv2.circle(canvas, (int((max_x-point[0])*x_scale), int((max_y - point[1])*y_scale)), 3, (0,0,255), cv2.FILLED)\n",
    "    else:\n",
    "        #Draw point\n",
    "        canvas = cv2.circle(canvas, [x//2 for x in canvas.shape[:2]], 3, (0,0,1), cv2.FILLED)\n",
    "    return canvas\n",
    "\n",
    "sift = cv2.SIFT_create()\n",
    "# sift = cv2.ORB_create(nfeatures=100000, edgeThreshold=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Detection framework\n",
    "This is a rudimentary detection framework. It uses the ground truth as detections with a probability of 0.5 that there's a detection available. If there's a detection available, this gives us an ROI on which we can compute SIFT features for either validation in the next frame or as a fallback solution if the detector does not give a detection in the next frame. \n",
    "\n",
    "It also includes a kalman filter that can be used to further increase reliability - tracking the plants helps to counteract missing detections as we have a prediction of either a) ROI or b) center location (and the plant size should be constant if the plant is not currently moving out of or into the frame)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_3118/2048598360.py:120: ComplexWarning: Casting complex values to real discards the imaginary part\n",
      "  minor = minor.astype(int)\n",
      "/tmp/ipykernel_3118/2048598360.py:122: ComplexWarning: Casting complex values to real discards the imaginary part\n",
      "  major = major.astype(int)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SIFT Compute TIME 0\t Frame processing time: 0.802039623260498\t sift ratio = 0.0\t sift ratio = 0.4123803610325406\r"
     ]
    }
   ],
   "source": [
    "cv2.namedWindow(\"test\", cv2.WINDOW_NORMAL)\n",
    "sequence = dataset.match_tags(\"20210806_hegnstrup_seq11\")\n",
    "kp, des = None, None\n",
    "img3 = None\n",
    "traj = []\n",
    "match_count = []\n",
    "\n",
    "#Kalman filter initialization\n",
    "#TODO Needs calibration\n",
    "kmf = KalmanNd(np.asarray([[0], [0], [0], [0]]), \n",
    "                        1000*np.eye(4),\n",
    "                        np.asarray([[1, 0, 0, 0], [0, 0, 0, 0], [0, 0, 1, 0], [0, 0, 0, 0]]),\n",
    "                        np.asarray([[0.2, 0, 0, 0], [0, 0, 0, 0], [0, 0, 0.2, 0], [0, 0, 0, 0]]),\n",
    "                        np.asarray([[1, 1, 0, 0], [0, 1, 0, 0], [0, 0, 1, 1], [0, 0, 0, 1]]))\n",
    "\n",
    "# FLANN parameters\n",
    "FLANN_INDEX_KDTREE = 1\n",
    "index_params = dict(algorithm = FLANN_INDEX_KDTREE, trees = 5)\n",
    "search_params = dict(checks=50)   # or pass empty dictionary\n",
    "flann = cv2.FlannBasedMatcher(index_params,search_params)\n",
    "\n",
    "\n",
    "#Sequence loop\n",
    "for frame in sequence:\n",
    "\n",
    "    sift_time = 0\n",
    "    load_time = time.time()\n",
    "    img, img_raw = draw_boxes(frame, {\"ground_truth_detections_single\" : (255,0,0),  \"predictions_yolov4_csp_single\" : (0,255,0)}, 0.5)\n",
    "    \n",
    "\n",
    "    #Use OpenCV to plot GPS path\n",
    "    canvas = np.zeros((1000,1000,3), dtype=np.uint8)\n",
    "    traj.append(frame[\"location\"].point)\n",
    "    canvas = plot_points(canvas, traj)\n",
    "    \n",
    "    #Kalman filter prediction\n",
    "    #Necessary / protocol for each step\n",
    "    kmf.predict()\n",
    "\n",
    "    if frame[\"ground_truth_detections_single\"] is not None:\n",
    "        \n",
    "        #Box and center extracted from ground truth (prototype detection)\n",
    "        box = frame[\"ground_truth_detections_single\"].detections[0].bounding_box\n",
    "        center = (box[0] + 0.5*box[2], box[1] + 0.5*box[3])\n",
    "\n",
    "        #Simulate availability with binomial draw, reliability -> probability\n",
    "        #TODO replace this by a detectors output\n",
    "        detection_available = np.random.binomial(1,0.5,1)\n",
    "\n",
    "        #Create the mask for the box in preparation for sift computation\n",
    "        #This would correspond to a detection -> gives RoI -> compute features from that and match it in the next\n",
    "        # a) Detection to verify\n",
    "        # b) Whole image to track RoI when no detection is there\n",
    "        if detection_available:\n",
    "            #Give me an ROI to detect features from\n",
    "            tl_x, tl_y, br_x, br_y = tlwhN2xyxy(box, frame[\"metadata\"].width, frame[\"metadata\"].height)        \n",
    "            box_mask = np.zeros((frame[\"metadata\"].height, frame[\"metadata\"].width), dtype=np.uint8)\n",
    "            box_mask[tl_y:(br_y+1), tl_x:(br_x+1)] = 1\n",
    "        else:\n",
    "            #Search for features in the whole frame\n",
    "            box_mask = None\n",
    "\n",
    "        #-----Compute the features---------\n",
    "        \n",
    "        #Timing the sift detection\n",
    "        start_time = time.time()\n",
    "        kp_curr, des_curr = sift.detectAndCompute(cv2.cvtColor(img_raw, cv2.COLOR_BGR2GRAY), box_mask)# if np.random.binomial(1,0.5,1) else None)\n",
    "        end_time = time.time()\n",
    "        sift_time += (end_time - start_time)\n",
    "\n",
    "        if kp is not None and des is not None:\n",
    "            \n",
    "            #Timing the flann matcher\n",
    "            start_time = time.time()\n",
    "            matches = flann.knnMatch(des, des_curr, k=2)\n",
    "            end_time = time.time()\n",
    "            sift_time += (end_time - start_time)\n",
    "            #match_count.append(len(matches)) \n",
    "\n",
    "            #Copied from OpenCV SIFT tutorial\n",
    "            # Need to draw only good matches, so create a mask\n",
    "            matchesMask = [[0,0] for i in range(len(matches))]\n",
    "            # ratio test as per Lowe's paper\n",
    "            for i,(m,n) in enumerate(matches):\n",
    "                if m.distance < 0.7*n.distance:\n",
    "                    matchesMask[i]=[1,0]\n",
    "            match_count.append(np.asarray(matchesMask).sum(axis=0)[0])\n",
    "\n",
    "            #TODO maybe move this out of the loop to only change the matchesMask value\n",
    "            draw_params = dict(matchColor = (0,255,0),\n",
    "                            singlePointColor = (255,0,0),\n",
    "                            matchesMask = matchesMask,\n",
    "                            flags = cv2.DrawMatchesFlags_DEFAULT)\n",
    "            img3 = cv2.drawMatchesKnn(img_prev,kp,img,kp_curr,matches,None,**draw_params)\n",
    "\n",
    "        #Keep keypoints and descriptors for next iteration (we have to)\n",
    "        #Think about the keypoints to keep when no detection is available and we do kalman/sift based tracking\n",
    "        #We only keep keypoints from detections (RoI keypoints)\n",
    "        if detection_available:\n",
    "            kp = kp_curr\n",
    "            des = des_curr \n",
    "            img_prev = img\n",
    "            \n",
    "            #Update the kalman filter as we have a detection\n",
    "            kmf.update(np.asarray([center[0], 0, center[1], 0]).reshape(-1,1))\n",
    "            \n",
    "            #Draw update point\n",
    "            cv2.circle(img, (int(center[0]*frame[\"metadata\"].width), int(center[1]*frame[\"metadata\"].height)), 10, (0,255, 0), cv2.FILLED)\n",
    "\n",
    "    canvas = np.pad(canvas, ((100,100), (460, 460), (0,0)), 'constant', constant_values=((0,0),(0,0),(0,0)))\n",
    "\n",
    "    #Draw kalman filter point on image\n",
    "    img = cv2.circle(img, (int(kmf.x_hist[-1][0]*frame[\"metadata\"].width), int(kmf.x_hist[-1][2]*frame[\"metadata\"].height)), 10, ((255, 0, 0) if kmf.updated[-1] else (0,0,255)), cv2.FILLED)\n",
    "\n",
    "    #-----------------Ellipsis drawing begin\n",
    "    center, minor, major = kmf.get_ellipsis(conf=0.5)\n",
    "    center = center.flatten() * np.asarray((frame[\"metadata\"].width, frame[\"metadata\"].height))\n",
    "    center = center.astype(int)\n",
    "    minor *= np.asarray((frame[\"metadata\"].width, frame[\"metadata\"].height))\n",
    "    minor = minor.astype(int)\n",
    "    major *= np.asarray((frame[\"metadata\"].width, frame[\"metadata\"].height))\n",
    "    major = major.astype(int)\n",
    "    #Draw kalman ellipsis onto image, angle is of major axis, + -> cw, - -> ccw\n",
    "    img = cv2.ellipse(img, center, (np.linalg.norm(major).astype(int), np.linalg.norm(minor).astype(int)), -np.arctan2(major[1], major[0]), 0, 360, ((255, 0, 0) if kmf.updated[-1] else (0,0,255)), 10)\n",
    "    #-----------------Ellipsis drawing end\n",
    "\n",
    "\n",
    "    #Save for next iteration\n",
    "    #img_prev = copy.deepcopy(img) \n",
    "    \n",
    "    #Merge plot and image together and display it\n",
    "    img = np.hstack((img, canvas))\n",
    "    if img3 is not None:\n",
    "        img = np.vstack((img, img3))\n",
    "    cv2.imshow(\"test\", img)\n",
    "    end_end_time = time.time()\n",
    "    print(f\"SIFT Compute TIME {sift_time}\\t Frame processing time: {end_end_time - load_time}\\t sift ratio = {sift_time/(end_end_time - load_time)}\\r\", end=\"\")\n",
    "    cv2.waitKey(1)\n",
    "    if chr(cv2.waitKey(0)) == 'q':\n",
    "        break\n",
    "    else:\n",
    "        pass\n",
    "    #max(1, int(abs(1e-3 - (time.time() - load_time)))*1000))\n",
    "    \n",
    "\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ORB matching and highlighting plant"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7.936169385910034\n",
      "2.238691806793213\n",
      "1.3414275646209717\n",
      "0.7367434501647949\n",
      "0.6375632286071777\n",
      "0.44980287551879883\n",
      "0.5715384483337402\n",
      "0.5356278419494629\n",
      "0.45821309089660645\n",
      "0.4354734420776367\n",
      "0.583411693572998\n",
      "0.4427509307861328\n",
      "0.44316649436950684\n",
      "0.5236375331878662\n",
      "0.4949984550476074\n",
      "0.4656486511230469\n",
      "0.7281689643859863\n",
      "0.4750967025756836\n",
      "0.47769951820373535\n",
      "0.5447378158569336\n",
      "0.4375758171081543\n",
      "0.49958038330078125\n",
      "0.4337494373321533\n",
      "0.44478940963745117\n",
      "0.6267051696777344\n",
      "0.525080680847168\n",
      "0.54937744140625\n",
      "0.5894832611083984\n",
      "0.748272180557251\n",
      "0.5173614025115967\n",
      "0.4323263168334961\n",
      "0.6256864070892334\n",
      "0.455324649810791\n",
      "0.6576087474822998\n",
      "0.6267027854919434\n",
      "0.44676804542541504\n",
      "0.456423282623291\n",
      "0.5294849872589111\n",
      "0.4483168125152588\n",
      "0.45849609375\n",
      "0.589806079864502\n",
      "0.4359738826751709\n",
      "0.4346449375152588\n",
      "0.5756247043609619\n",
      "0.44915103912353516\n",
      "0.43576478958129883\n",
      "0.6055753231048584\n",
      "0.4263150691986084\n",
      "0.441361665725708\n",
      "0.5756096839904785\n",
      "0.45145750045776367\n",
      "0.42442870140075684\n",
      "0.5289871692657471\n",
      "0.6715481281280518\n",
      "0.46500635147094727\n",
      "0.5210604667663574\n",
      "0.43900394439697266\n",
      "0.4501965045928955\n",
      "0.5421676635742188\n",
      "0.44348859786987305\n",
      "0.4400758743286133\n",
      "0.5340416431427002\n",
      "0.4223818778991699\n",
      "0.46550631523132324\n",
      "0.5522427558898926\n",
      "0.4400913715362549\n",
      "0.4359109401702881\n",
      "0.5455970764160156\n",
      "0.4497215747833252\n",
      "0.5130963325500488\n",
      "0.4376332759857178\n",
      "0.44283151626586914\n",
      "0.5257949829101562\n",
      "0.43433713912963867\n",
      "0.5410525798797607\n",
      "0.44167280197143555\n",
      "0.48946070671081543\n",
      "0.5358173847198486\n",
      "0.4334251880645752\n",
      "0.4366753101348877\n",
      "0.5312268733978271\n",
      "0.47533631324768066\n",
      "0.49391818046569824\n",
      "0.5452480316162109\n",
      "0.403095006942749\n",
      "0.4200575351715088\n",
      "0.6494123935699463\n",
      "0.45940375328063965\n",
      "0.42534852027893066\n",
      "0.5248041152954102\n",
      "0.44983768463134766\n",
      "0.42788028717041016\n",
      "0.6023433208465576\n",
      "0.4512348175048828\n",
      "0.43662500381469727\n",
      "0.5962412357330322\n",
      "0.42458605766296387\n",
      "0.45176124572753906\n",
      "0.6468961238861084\n",
      "0.537106990814209\n",
      "0.44297003746032715\n",
      "0.43973231315612793\n",
      "0.44057416915893555\n",
      "0.639031171798706\n",
      "0.49619364738464355\n",
      "0.4633312225341797\n",
      "0.6128511428833008\n",
      "0.454664945602417\n",
      "0.45736050605773926\n",
      "0.6375713348388672\n",
      "0.43386220932006836\n",
      "0.4920539855957031\n",
      "0.624500036239624\n",
      "0.44313788414001465\n",
      "0.4426231384277344\n",
      "0.581810474395752\n",
      "0.6277549266815186\n",
      "0.44284796714782715\n",
      "0.4519681930541992\n",
      "0.5925705432891846\n",
      "0.6196415424346924\n",
      "0.44394350051879883\n",
      "0.6206245422363281\n",
      "0.5154454708099365\n",
      "0.5140814781188965\n",
      "0.523289680480957\n",
      "0.7146596908569336\n",
      "0.44183802604675293\n",
      "0.5456507205963135\n",
      "0.6350524425506592\n",
      "0.5910511016845703\n",
      "0.5584728717803955\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "920c323eee9e4f72844a3650cbef6b8f",
       "version_major": 2,
       "version_minor": 0
      },
      "image/png": "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",
      "text/html": [
       "\n",
       "            <div style=\"display: inline-block;\">\n",
       "                <div class=\"jupyter-widgets widget-label\" style=\"text-align: center;\">\n",
       "                    Figure\n",
       "                </div>\n",
       "                <img src='data:image/png;base64,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' width=640.0/>\n",
       "            </div>\n",
       "        "
      ],
      "text/plain": [
       "Canvas(toolbar=Toolbar(toolitems=[('Home', 'Reset original view', 'home', 'home'), ('Back', 'Back to previous …"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "cv2.namedWindow(\"test\", cv2.WINDOW_NORMAL)\n",
    "sequence = dataset.match_tags(\"20210806_hegnstrup_seq11\")\n",
    "kp_list = []\n",
    "for frame in sequence:\n",
    "    img = cv2.imread(frame.filepath)\n",
    "    #kp_list.append(sift.detect(cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)))# if np.random.binomial(1,0.5,1) else None))\n",
    "    start_time = time.time()\n",
    "    kp = sift.detect(cv2.cvtColor(img, cv2.COLOR_BGR2GRAY))\n",
    "    end_time = time.time()\n",
    "    sift_time = end_time - start_time\n",
    "    img, img_raw = draw_boxes(frame, {'ground_truth_detections_single' : (0,0,255)})\n",
    "    img = cv2.drawKeypoints(img ,kp,img, color=(255,0,0))\n",
    "    points = np.asarray([x.pt for x in kp])\n",
    "    h,x,y, _ = plt.hist2d(points[:, 0], points[:, 1], bins=(19,12), cmap='gray')\n",
    "    plt.axis('off')\n",
    "    plt.savefig(\"test.png\", bbox_inches='tight', pad_inches=0)\n",
    "    hist = cv2.resize(cv2.imread(\"test.png\"), (1920,1200))\n",
    "    hist = cv2.GaussianBlur(hist, (19,11), 10.0)\n",
    "    hist = np.flipud(hist)\n",
    "    #img = cv2.addWeighted(img, 1.3 , hist, -0.3, 0.0)\n",
    "    img_proc = cv2.addWeighted(img_raw, 1.3, hist, -0.3, 0.0)\n",
    "    img = np.hstack((img, img_proc))\n",
    "    img = np.vstack((img, np.hstack((img_raw, img_proc))))\n",
    "    cv2.imshow(\"test\", img)\n",
    "    cv2.waitKey(1)\n",
    "    print(sift_time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "area_fn = lambda x: x[2]*x[3]\n",
    "for key in bbox_dict:\n",
    "    area = []\n",
    "    box_count = []\n",
    "    detections = bbox_dict[key]\n",
    "    fig = plt.figure()\n",
    "    ax = plt.axes()\n",
    "    for detection in detections:\n",
    "        if detection is not None:\n",
    "            bbox_array = np.asarray(detection).reshape(-1,4)\n",
    "            area.append(np.cumsum(np.apply_along_axis(area_fn, 1, bbox_array)[-1]))\n",
    "            box_count.append(bbox_array.shape[0])\n",
    "    ax.plot(area)\n",
    "    ax.twinx().plot(box_count, color='yellow')\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# IMU, GPS and Odometry data\n",
    "This section analyzes the relationships between the data and how to make use of these to make a reliable weed detection framework "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "e42a55181f121158a42f92e69485864b9ecfda4e76420aabfd16d5b20265c656"
  },
  "kernelspec": {
   "display_name": "Python 3.9.10 ('yolov5')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
